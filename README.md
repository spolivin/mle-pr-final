# Recommendation system in e-commerce

## Objective

Цель данного репозитория состоит в построении рекомендательной системы товаров для пользователей, а также ее выкатке с production-среду и поддержке при помощи различных фреймворков и сервисов.


## Metrics

Задачей, которую нам предстоит решить для достижения цели, является оптимизация системы рекомендаций для действий пользователей по добавлению товаров в корзину посредством максимизации следующих метрик:

* `precision@10`
* `recall@10`

Выбор этих метрик обусловлен их частотностью использования для оценивания качества рекомендательных систем, а также тем, что в данном случае наш фокус будет на релевантности рекомендаций для пользователей, что данные метрики позволяют математически рассчитать. Скорее всего пользователи увидят только некоторую часть рекомендаций, поэтому в данной задаче будем рассматривать первые 10 рекомендаций и на основе них делать выводы о качестве различных рекомендаций.

Метрика `precision@10` позволит нам сказать, нравится ли рекомендованный товар пользователю, а посредством `recall@10` мы сможем судить о способности модели находить и предугадывать все предпочтения пользователя. 

## Project structure

Проект разделен в целом на несколько блоков, каждый из которых поименован и описан в таблице ниже:

| Component | Description | Frameworks | Link    |
| :---   | :--- | :---: | :---: |
| **Modeling experiments** | Разворачивание сервиса *Mlflow* с хранилищем артефактов и построение и оптимизация системы рекомендаций товаров | `mlflow` `catboost` `implicit` `sklearn`| [recsys](./recsys/) |
| **Pipelines** | Развертывание мультиконтейнерного сервисе *Airflow* в среде *Docker* и создание пайплайнов загрузки данных и переобучения модели | `docker` `docker-compose` `airflow` `catboost` | [airflow_service](./airflow_service/) |
| **Web-service deployment** | Развертывание *FastAPI* сервиса рекомендаций в среде *Docker* с дополнительным мониторингом метрик через *Prometheus* и *Grafana*| `docker` `docker-compose` `fastapi` `prometheus` `grafana` `requests`| [fastapi_service](./fastapi_service/) |

Переходя на каждую из ссылок в последней колонке таблицы, можно переходить в соответствующую директорию с подробным описанием в соответствующем `README`.

## Additional toolbox
В качестве дополнительных инструментов работы с облачным хранилищем *S3* и базой данных *PostgreSQL*, есть отдельные папки для автоматизации некоторых рутинных задач:

| Component | Description | Frameworks | Link    |
| :---   | :--- | :---: | :---: |
| **S3 Object Storage** | Сборка скриптов для отправки файлов в облако, а также просмотр содержания *S3*-бакета и доступного места | `boto3` | [s3_scripts](./s3_scripts/) |
| **PostgreSQL** | Сборка скриптов для удаления, загрузки и просмотра таблиц из *Postgres* | `psycopg2` | [postgres_scripts](./postgres_scripts/) |

### Interacting with S3

В папке [s3_scripts](./s3_scripts/) можно найти скрипты для удобного взаимодействия с облачным хранилищем. На данный момент ряд действий включает самые основные:

1. **Просмотр содержимого хранилища**

Для просмотра файлов в бакете можно воспользоваться следующей командой:
```bash
python s3_scripts/check_storage.py --option=contents
```

При необходимости можно вывести и размер файла, запустив:

```bash
python s3_scripts/check_storage.py --option=space
```

2. **Загрузка файлов в S3**

Если нужно загрузить какой-то файл в облачное хранилище вне системы экспериментов *Mlflow*, то можно использовать следующую команду для случайного файла:

```bash
python s3_scripts/push_file.py --local-file-path=data/test.parquet --s3-file-path=recsys/test/test.parquet
```

>Note: в данном случае необходимо прописать полный путь до файла в локальной директории и желаемый путь до файла в облачном хранилище

### Interacting with Postgres

На данный момент есть следующие скрипты для произведения действий с базой данных:

1. **Просмотр таблицы**

```bash
python postgres_scripts/show_table.py --table-name=<table_name>
```

2. **Загрузка таблицы из БД в локальную директорию**

```bash
python postgres_scripts/load_table.py --save-dir=<save_dir> --table-name=<table_name>
```

>Note: При запуске скрипта из корневой директории нет необходимости указывать `--save-dir`, нужная таблица загрузится в нужную директорию в соответствии с дефолтным путем

3. **Удаление таблицы из БД**

```bash
python postgres_scripts/drop_table.py --table-name=<table_name>
```
