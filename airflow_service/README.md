# Pipelines

Данная директория посвящена запуску сервиса *Airflow* и выполнению различных *DAG*-ов. 

## Directory structure

В данной директории присутствуют следующие структуры и файлы:

| Element | Description |
| :---   | :--- |
| [`config`](./config/)| Конфигурационные файлы *Airflow* |
| [`dags`](./dags/)| Скрипты запуска графов *Airflow* |
| [`logs`](./logs/)| Логи с результами запусков *DAG*-ов |
| [`plugins`](./plugins/)| Дополнительные модули для запуска графов |
| [`Dockerfile`](./Dockerfile)| Кастомный *Dockerfile* |
| [`docker-compose.yaml`](./docker-compose.yaml)| Файл с инструкциями запуска сервисов |
| [`requirements-airflow.txt`](./requirements-airflow.txt)| Зависимости для запуска сервисов |
| [`postgres_data`](./postgres_data/)| Данные для загрузки в базу данных, полученные на этапе экспериментов и моделирования |

## Airflow service

Для запуска сервиса *Airflow* мы заранее создали несколько папок:

* `config` => Хранение кастомных конфиг-файлов
* `dags` => Хранение графов
* `logs` => Хранение логов сервиса
* `plugins` => Хранение дополнительных модулей для выполнения *DAG*-ов

Разработчики *Airflow* подготовили множество инструкций по запуску сервисов, одной из которых является [`docker-compose.yaml`](./docker-compose.yaml) файл, который был предзагружен командой:

```bash
curl -LfO https://airflow.apache.org/docs/apache-airflow/2.7.3/docker-compose.yaml
```

Поскольку мы будем использовать свое расширение образа из данного конфига, также был добавлен свой [`Dockerfile`](./Dockerfile), который используется при сборке образа.

>Note: Для ожидаемой работы сервиса было необходимо закоментировать строку 53 и раскоментировать строку 54 в [`docker-compose.yaml`](./docker-compose.yaml) для расширения образа (инструкция разработчиков Airflow)

### Запуск сервиса

Шаги ниже описывают последовательность коректного запуска сервисов *Airflow*:

1. **Сохранение ID виртуальной машины**

```bash
echo -e "\nAIRFLOW_UID=$(id -u)" >> .env
```
2. **Создание учетной записи с логином и паролем**

```bash
cd airflow_service
docker compose up airflow-init
```

3. **Очистка кэша после Шага 2**

```bash
docker compose down --volumes --remove-orphans
```

4. **Запуск**

```bash
docker compose up --build
```

### DAGs

В папке [`dags`](./dags/) хранятся различные графы с установленными периодами запуска:

| DAG | Purpose | Schedule (CRON) | Schedule (Periodicity) |
| :---   | :--- | :--- | :--- |
| [`load_default_recs.py`](./dags/load_default_recs.py)| Загрузка дефолтных рекомендаций в БД | *5 21 * * 6* | Каждую субботу в 21:05 |
| [`load_online_recs.py`](./dags/load_online_recs.py)| Загрузка онлайн рекомендаций в БД | *5 21 * * 6* | Каждую субботу в 21:05 |
| [`load_candidates_train.py`](./dags/load_candidates_train.py)| Загрузка тренировочных рекомендаций в БД | *10 21 * * 6* | Каждую субботу в 21:10 |
| [`load_candidates_inference.py`](./dags/load_candidates_inference.py)| Загрузка тестовых рекомендаций в БД | *10 21 * * 6* | Каждую субботу в 21:10 |
| [`load_candidates_ranked.py`](./dags/load_candidates_ranked.py)| Тренировка модели на тренировочных рекомендациях и ранжирование тестовых рекомендаций | *15 21 * * 6* | Каждую субботу в 21:15 |

Другими словами, мы недельно запланировали раны пайплайнов:

* **Суббота 21:05** => Новые дефолтные и онлайн-рекомендации загружаются в базу данных;
* **Суббота 21:10** => Загружаются тренировочные рекомендации для обучения модели, а также тестовые, которые нужно отранжировать;
* **Суббота 21:15** => Модель обучается заново на новых тренировочных данных, а далее эта информация используется для ранжирования тестовых рекомендаций, которые затем также загружаются в базу данных.

**Note:** Пожалуй, главным недостатком сервиса в текущей версии является то, что в случае обновления файлов в `postgres_data` придется пересобирать все сервисы заново, чтобы обновления попали в контейнер. Не было найдено альтернативного способа монтирования локальной директории к сервисам *Airflow*

### Plugins 

Также есть папка `plugins` с папкой [`steps`](./plugins/steps) с дополнительными модулями, описывающими шаги пайплайнов:

| DAG | Purpose |
| :---   | :--- |
| [`default_recs.py`](./plugins/steps/default_recs.py)|Загрузка дефолтных рекомендаций в БД |
| [`online_recs.py`](./plugins/steps/online_recs.py)| Загрузка онлайн рекомендаций в БД |
| [`training_data.py`](./plugins/steps/training_data.py)| Загрузка тренировочных рекомендаций в БД |
| [`inference_data.py`](./plugins/steps/inference_data.py)| Загрузка тестовых рекомендаций в БД |
| [`ranked_data.py`](./plugins/steps/ranked_data.py)| Тренировка модели на тренировочных рекомендациях и ранжирование тестовых рекомендаций |
| [`messages.py`](./plugins/steps/messages.py)| Коллбэки для сообщений о ходе выполнения *DAG* в *Telegram*|

Итак, в результате выполнения графов данные, загруженные после выполнения кода в [тетрадке](../recsys/recommendation_system.ipynb), отправляются в базу данных, где после выполнения графа `load_candidates_ranked.py` мы получаем (помимо других рекомендаций) персональные рекомендации для их использования в сервисе.

На следующем шаге мы загружаем данные из базы данных в [папку с веб-сервисом](../fastapi_service/), откуда все три типа рекомендаций будут использоваться для выполнения запросов.

## Остановка сервисов

Для остановки всех сервисов после окончания работы с *Airflow* запускаем следующие команды:

```bash
cd airflow_service
docker compose down
```